{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as wb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "h1 = 200\n",
    "h2 = 100\n",
    "\n",
    "stock_list = [\"AAPL\",\"MSFT\"]\n",
    "\n",
    "num_stocks = len(stock_list)\n",
    "lookback = 30\n",
    "predictions = 10\n",
    "periods = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ticker):\n",
    "    df = wb.DataReader(ticker, \"yahoo\", \"2010-01-01\")\n",
    "    df = df[[\"Adj Close\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(*dfs):\n",
    "    for df in dfs:\n",
    "        plt.plot(df, label = f\"stock_list{i for i in stock_list}\")\n",
    "    plt.legend(loc = 4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = [ get_data(ticker) for ticker in stock_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "args = [ df.values.reshape(df.shape[0],1) for df in stocks]\n",
    "\n",
    "n_args = len(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = scaler.fit_transform(np.concatenate((args[0],args[1]), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = len(np_arr) - periods * predictions\n",
    "\n",
    "train = np_arr[: div]\n",
    "test = np_arr[div - lookback:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64971501, 0.70454294],\n",
       "       [0.64131972, 0.70978956],\n",
       "       [0.61477023, 0.67556933],\n",
       "       [0.61950053, 0.69726035],\n",
       "       [0.61536682, 0.70509108],\n",
       "       [0.61736975, 0.70892814],\n",
       "       [0.6252536 , 0.71182552],\n",
       "       [0.60194286, 0.68504442],\n",
       "       [0.59538012, 0.66045602],\n",
       "       [0.60445723, 0.66891319],\n",
       "       [0.58238238, 0.66672062],\n",
       "       [0.56508049, 0.64964972],\n",
       "       [0.53908488, 0.62396491],\n",
       "       [0.52246487, 0.591859  ],\n",
       "       [0.56652934, 0.64221052],\n",
       "       [0.56218261, 0.6470655 ],\n",
       "       [0.56252348, 0.64087926],\n",
       "       [0.56895849, 0.6501195 ],\n",
       "       [0.56972558, 0.64659572],\n",
       "       [0.50269125, 0.61746544],\n",
       "       [0.52855887, 0.65293857],\n",
       "       [0.5271526 , 0.65395655],\n",
       "       [0.5391701 , 0.65975126],\n",
       "       [0.55007969, 0.67126244],\n",
       "       [0.55216791, 0.66601581],\n",
       "       [0.54573297, 0.65975126],\n",
       "       [0.53597398, 0.65387831],\n",
       "       [0.54905701, 0.6770572 ],\n",
       "       [0.55702614, 0.67995447],\n",
       "       [0.56094678, 0.68574924],\n",
       "       [0.56503778, 0.69820002],\n",
       "       [0.55003718, 0.68230371],\n",
       "       [0.55267928, 0.6903693 ],\n",
       "       [0.54748017, 0.68637569],\n",
       "       [0.56904364, 0.6939715 ],\n",
       "       [0.56282178, 0.67760535],\n",
       "       [0.55591804, 0.66084761],\n",
       "       [0.60096275, 0.68778526],\n",
       "       [0.60603406, 0.67251533],\n",
       "       [0.60637493, 0.65959471],\n",
       "       [0.62653213, 0.68277355],\n",
       "       [0.63901843, 0.69436309],\n",
       "       [0.63927415, 0.68504442],\n",
       "       [0.62521109, 0.6790931 ],\n",
       "       [0.62606695, 0.68222541],\n",
       "       [0.6218727 , 0.67893655],\n",
       "       [0.62812128, 0.69177887],\n",
       "       [0.62508257, 0.69115242],\n",
       "       [0.62773618, 0.69185723],\n",
       "       [0.62610979, 0.70219375],\n",
       "       [0.62829244, 0.70180216],\n",
       "       [0.63300031, 0.69739829],\n",
       "       [0.62884889, 0.71517129],\n",
       "       [0.63702334, 0.7274393 ],\n",
       "       [0.64241598, 0.73231506],\n",
       "       [0.64284398, 0.73837049],\n",
       "       [0.64515501, 0.73687627],\n",
       "       [0.63779372, 0.73577527],\n",
       "       [0.64558301, 0.73970744],\n",
       "       [0.64934933, 0.73758411],\n",
       "       [0.64797972, 0.73318012],\n",
       "       [0.64365714, 0.73357334],\n",
       "       [0.63501185, 0.72287816],\n",
       "       [0.63676656, 0.72382182],\n",
       "       [0.66240274, 0.74206665],\n",
       "       [0.67100532, 0.74827935],\n",
       "       [0.67442912, 0.75519977],\n",
       "       [0.68307434, 0.75590755],\n",
       "       [0.69330318, 0.76628824],\n",
       "       [0.70143492, 0.77934269],\n",
       "       [0.69505795, 0.77997186],\n",
       "       [0.70203408, 0.77894947],\n",
       "       [0.73169329, 0.80018274],\n",
       "       [0.71440278, 0.77525337],\n",
       "       [0.70451633, 0.78005053],\n",
       "       [0.69617066, 0.78201658],\n",
       "       [0.70336079, 0.77305138],\n",
       "       [0.70443072, 0.77430971],\n",
       "       [0.70969491, 0.78225246],\n",
       "       [0.71521594, 0.79074571],\n",
       "       [0.72711394, 0.79208265],\n",
       "       [0.73280613, 0.79821669],\n",
       "       [0.73426122, 0.7934196 ],\n",
       "       [0.7398678 , 0.79758758],\n",
       "       [0.75313528, 0.79790213],\n",
       "       [0.75056741, 0.79279043],\n",
       "       [0.75536076, 0.79994679],\n",
       "       [0.74821347, 0.80104785],\n",
       "       [0.74787109, 0.80592355],\n",
       "       [0.74941179, 0.80671   ],\n",
       "       [0.74949741, 0.804508  ],\n",
       "       [0.76610321, 0.81237214],\n",
       "       [0.76922753, 0.82495483],\n",
       "       [0.77209501, 0.82802181],\n",
       "       [0.78472049, 0.84123367],\n",
       "       [0.78335094, 0.83785206],\n",
       "       [0.77530488, 0.87040962],\n",
       "       [0.77111062, 0.87622905],\n",
       "       [0.7724374 , 0.87528539],\n",
       "       [0.75557476, 0.88181258],\n",
       "       [0.79773119, 0.8604221 ],\n",
       "       [0.79186784, 0.84728903],\n",
       "       [0.80299538, 0.86844351],\n",
       "       [0.78900029, 0.86254542],\n",
       "       [0.76494766, 0.84186271],\n",
       "       [0.76511882, 0.8417841 ],\n",
       "       [0.75578882, 0.8417055 ],\n",
       "       [0.743888  , 0.85452401],\n",
       "       [0.69465226, 0.82479755],\n",
       "       [0.7072834 , 0.83565007],\n",
       "       [0.71699309, 0.84946323],\n",
       "       [0.71338417, 0.87243265],\n",
       "       [0.70874415, 0.86564455],\n",
       "       [0.6833529 , 0.85104192],\n",
       "       [0.69843299, 0.85640939],\n",
       "       [0.68202106, 0.86248718],\n",
       "       [0.66861657, 0.85072622],\n",
       "       [0.66565209, 0.8511998 ],\n",
       "       [0.66247282, 0.85056834],\n",
       "       [0.65882094, 0.84093857],\n",
       "       [0.66277356, 0.84717423],\n",
       "       [0.64889646, 0.83099303],\n",
       "       [0.64129195, 0.80068291],\n",
       "       [0.66853063, 0.82688855],\n",
       "       [0.68098988, 0.84796358],\n",
       "       [0.6925041 , 0.86367113],\n",
       "       [0.71368491, 0.89192893],\n",
       "       [0.72412498, 0.90140094],\n",
       "       [0.73370576, 0.89745434],\n",
       "       [0.73104207, 0.89263948],\n",
       "       [0.73087012, 0.89919085],\n",
       "       [0.72481238, 0.90021692],\n",
       "       [0.72975314, 0.9033743 ],\n",
       "       [0.74934434, 0.92160777],\n",
       "       [0.74685248, 0.92579111],\n",
       "       [0.75368364, 0.93573658],\n",
       "       [0.75076213, 0.93589452],\n",
       "       [0.7499029 , 0.94228807],\n",
       "       [0.73697097, 0.90795231],\n",
       "       [0.75514439, 0.91189891],\n",
       "       [0.75488663, 0.91363542],\n",
       "       [0.74706727, 0.91213588],\n",
       "       [0.76266295, 0.9257122 ],\n",
       "       [0.76773255, 0.93281617],\n",
       "       [0.77495038, 0.93976221],\n",
       "       [0.77417704, 0.93660484],\n",
       "       [0.75608956, 0.93581561],\n",
       "       [0.76133111, 0.93186901],\n",
       "       [0.76988071, 0.94284068],\n",
       "       [0.76352218, 0.94718183],\n",
       "       [0.77018151, 0.95112844],\n",
       "       [0.77838748, 0.95112844],\n",
       "       [0.77533706, 0.93676278],\n",
       "       [0.7703963 , 0.93036923],\n",
       "       [0.78032079, 0.93155325],\n",
       "       [0.76713109, 0.93313182],\n",
       "       [0.78702303, 0.94741856],\n",
       "       [0.79398303, 0.95420678],\n",
       "       [0.79325272, 0.96549421],\n",
       "       [0.7861638 , 0.96131088],\n",
       "       [0.78925713, 0.97038798],\n",
       "       [0.79759194, 0.96794116],\n",
       "       [0.79372527, 0.96257381],\n",
       "       [0.8120276 , 0.93036923],\n",
       "       [0.79222154, 0.94449816],\n",
       "       [0.77327484, 0.93534191],\n",
       "       [0.72739012, 0.89832259],\n",
       "       [0.74311465, 0.9178979 ],\n",
       "       [0.75187911, 0.92255494],\n",
       "       [0.77073994, 0.95104952],\n",
       "       [0.7635379 , 0.94173557],\n",
       "       [0.76133841, 0.92658045],\n",
       "       [0.79795276, 0.94876052],\n",
       "       [0.77112813, 0.91581518],\n",
       "       [0.76677238, 0.91343929],\n",
       "       [0.78730053, 0.93284228],\n",
       "       [0.80390422, 0.95089883],\n",
       "       [0.80394733, 0.94179128],\n",
       "       [0.81378014, 0.95390818],\n",
       "       [0.8130039 , 0.94590948],\n",
       "       [0.77065373, 0.91114268],\n",
       "       [0.78725743, 0.92745692],\n",
       "       [0.77720897, 0.92975366],\n",
       "       [0.78311726, 0.92832808],\n",
       "       [0.79812523, 0.9486021 ],\n",
       "       [0.79696087, 0.94654306],\n",
       "       [0.7838504 , 0.93212943],\n",
       "       [0.79890154, 0.9447216 ],\n",
       "       [0.81654023, 0.96388689],\n",
       "       [0.81645396, 0.95636334],\n",
       "       [0.82037848, 0.94385044],\n",
       "       [0.83128945, 0.93244628],\n",
       "       [0.86100354, 0.932763  ],\n",
       "       [0.85884722, 0.94385044],\n",
       "       [0.84013038, 0.94226656],\n",
       "       [0.84508989, 0.93442616],\n",
       "       [0.84854001, 0.94282086],\n",
       "       [0.85746721, 0.95176999],\n",
       "       [0.84966134, 0.97196486],\n",
       "       [0.83573147, 0.95905596],\n",
       "       [0.840001  , 0.95668007],\n",
       "       [0.83551582, 0.94274171],\n",
       "       [0.84996319, 0.95842238],\n",
       "       [0.84504679, 0.95984784],\n",
       "       [0.84043229, 0.94551348],\n",
       "       [0.86264237, 0.95580891],\n",
       "       [0.86531618, 0.94028667],\n",
       "       [0.84103606, 0.92112126],\n",
       "       [0.84905758, 0.93403016],\n",
       "       [0.87575277, 0.9486021 ],\n",
       "       [0.87596841, 0.94068255],\n",
       "       [0.86449677, 0.92919923],\n",
       "       [0.87583904, 0.94955253],\n",
       "       [0.88903571, 0.95636334],\n",
       "       [0.91542911, 0.96095657],\n",
       "       [0.91396277, 0.95992711],\n",
       "       [0.91159087, 0.97592463],\n",
       "       [0.9074938 , 0.96673793],\n",
       "       [0.91141832, 0.96103584],\n",
       "       [0.91629163, 0.94297929],\n",
       "       [0.93397342, 0.95105714],\n",
       "       [0.93160152, 0.93474289],\n",
       "       [0.94548816, 0.94163298],\n",
       "       [0.94721325, 0.96301573],\n",
       "       [0.96015118, 0.96927212],\n",
       "       [0.9708034 , 0.9966738 ],\n",
       "       [0.94596255, 0.98590322],\n",
       "       [0.94583318, 1.        ],\n",
       "       [0.9695527 , 0.99017972],\n",
       "       [1.        , 0.99295161]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01004369, 0.04539697],\n",
       "       [0.01180722, 0.04833676],\n",
       "       [0.01200618, 0.04839927],\n",
       "       ...,\n",
       "       [0.54905701, 0.6770572 ],\n",
       "       [0.55702614, 0.67995447],\n",
       "       [0.56094678, 0.68574924]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess( df, lookback, prediction_days, n_stocks, jump =1):\n",
    "    x,y = [],[]\n",
    "    for i in range(0, len(df)-lookback-prediction_days + 1, jump):\n",
    "        x.append(df[i:(i+lookback)])\n",
    "        y.append(df[(i+lookback):(i + lookback + prediction_days)])\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = preprocess(test, lookback, predictions, num_stocks, predictions)\n",
    "y_test = np.array([list(a.ravel()) for a in y_test])\n",
    "\n",
    "x, y = preprocess(train, lookback, predictions, num_stocks)\n",
    "y = np.array([list(b.ravel()) for b in y])\n",
    "\n",
    "x_train , x_val , y_train, y_val = train_test_split(x, y, test_size = 0.30, random_state = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1566, 30, 2)\n",
      "(672, 30, 2)\n",
      "(20, 30, 2)\n",
      "(1566, 20)\n",
      "(672, 20)\n",
      "(20, 20)\n"
     ]
    }
   ],
   "source": [
    "#Dimensions - (Sample,Timestep,Features)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ayush\\Anaconda2019\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(h1, input_shape = (lookback,num_stocks),return_sequences = True))\n",
    "model.add(LSTM(h2, input_shape = (h1, 1)))\n",
    "model.add(Dense(predictions * num_stocks))\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ayush\\Anaconda2019\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1566 samples, validate on 672 samples\n",
      "Epoch 1/300\n",
      " - 199s - loss: 0.0017 - val_loss: 5.7387e-04\n",
      "Epoch 2/300\n",
      " - 190s - loss: 8.8688e-04 - val_loss: 5.1451e-04\n",
      "Epoch 3/300\n",
      " - 200s - loss: 5.9309e-04 - val_loss: 3.4571e-04\n",
      "Epoch 4/300\n",
      " - 196s - loss: 5.3109e-04 - val_loss: 3.6451e-04\n",
      "Epoch 5/300\n",
      " - 191s - loss: 4.8260e-04 - val_loss: 2.7995e-04\n",
      "Epoch 6/300\n",
      " - 191s - loss: 4.7793e-04 - val_loss: 3.2214e-04\n",
      "Epoch 7/300\n",
      " - 197s - loss: 4.0267e-04 - val_loss: 6.7442e-04\n",
      "Epoch 8/300\n",
      " - 191s - loss: 3.7447e-04 - val_loss: 7.2169e-04\n",
      "Epoch 9/300\n",
      " - 193s - loss: 3.5978e-04 - val_loss: 2.7101e-04\n",
      "Epoch 10/300\n",
      " - 191s - loss: 3.4634e-04 - val_loss: 2.7034e-04\n",
      "Epoch 11/300\n",
      " - 192s - loss: 3.5342e-04 - val_loss: 3.5068e-04\n",
      "Epoch 12/300\n",
      " - 192s - loss: 3.4354e-04 - val_loss: 3.3950e-04\n",
      "Epoch 13/300\n",
      " - 194s - loss: 3.2978e-04 - val_loss: 2.5861e-04\n",
      "Epoch 14/300\n",
      " - 189s - loss: 3.1435e-04 - val_loss: 4.5012e-04\n",
      "Epoch 15/300\n",
      " - 193s - loss: 3.3075e-04 - val_loss: 2.6253e-04\n",
      "Epoch 16/300\n",
      " - 194s - loss: 3.0534e-04 - val_loss: 4.5700e-04\n",
      "Epoch 17/300\n",
      " - 193s - loss: 3.1998e-04 - val_loss: 2.8851e-04\n",
      "Epoch 18/300\n"
     ]
    }
   ],
   "source": [
    "Sess = model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),shuffle=True,batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (13,10))\n",
    "plt.plot(sess.sess[\"loss\"],label = \"Loss\")\n",
    "plt.plot(sess.sess[\"val_loss\"], label = \"Val Loss\")\n",
    "plt.legend(loc = 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test , y_test = preprocess(test , lookback, predictions, num_stocks, predictions)\n",
    "y_test = np.array([list(a.ravel() for a in y_test)])\n",
    "\n",
    "x_h = model.predict(x_test)\n",
    "x_h.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transformation(results,num_stocks):\n",
    "    #From input/output nootbook: apply makeup, use scl.inverse_transform and remove makeup\n",
    "    \n",
    "    #transform to input shape\n",
    "    original_matrix_format = []\n",
    "    for result in results:\n",
    "        #do inverse transform\n",
    "        original_matrix_format.append(scl.inverse_transform([result[x:x+num_companies] for x in range(0, len(result), num_stocks)]))\n",
    "    original_matrix_format = np.array(original_matrix_format)\n",
    "    \n",
    "    #restore to original shape\n",
    "    for i in range(len(original_matrix_format)):\n",
    "        results[i] = original_matrix_format[i].ravel()\n",
    "\n",
    "    return output_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_by_company(raw_model_output, num_stocks):\n",
    "    matrix_prediction = []\n",
    "    for i in range(0,num_stocks):\n",
    "        matrix_prediction.append([[lista[j] for j in range(i,len(lista),num_stocks)] for lista in raw_model_output])\n",
    "    return np.array(matrix_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_h = inverse_transformation(x_h,num_stocks)\n",
    "\n",
    "x_h1 = prediction_by_company(x_h, num_stocks)\n",
    "x_h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_by_company(raw_model_output, num_stocks):\n",
    "    matrix_target = [[] for x in range(num_stocks)]\n",
    "    \n",
    "    for output in raw_model_output:\n",
    "        for i in range (num_stocks):\n",
    "            for j in range(0,len(output),num_stocks):\n",
    "                matrix_target[i].append(output[i+j])\n",
    "    return np.array(matrix_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h = inverse_transformation(y_test)\n",
    "\n",
    "y_h1 = target_by_company(y_h, num_stocks)\n",
    "y_h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
